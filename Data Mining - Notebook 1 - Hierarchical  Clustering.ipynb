{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Clustering, we try to group the variables which are similar to each other. We measure the similarities with respect to distance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:08:06.107285Z",
     "start_time": "2020-03-12T07:08:04.262327Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:11:04.723452Z",
     "start_time": "2020-03-12T07:11:04.711697Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:11:21.953490Z",
     "start_time": "2020-03-12T07:11:21.912094Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cust_Spend_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data is of supermarkets and the visits of customers and their spendings in the supermarket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the explanation of the dataframe loaded in the previous step.\n",
    "\n",
    "$\\underline{CustID}$: This is a number kept by the supermarket to identify the customer on their next visit to the supermarket.\n",
    "\n",
    "$\\underline{Name}$: This refers to the name of the customer. Here, to maintain anonymity we have letters in place of the actual names of customers.\n",
    "\n",
    "$\\underline{AvgMthlySpend}$: The amount of money spent in the Supermarket by the customer.\n",
    "\n",
    "$\\underline{NoofVisits}$: The number of visits by the customer to the supermarket.\n",
    "\n",
    "$\\underline{ApparelItems}$: The number of apparel items bought by the customer on his visits to the Supermarket.\n",
    "\n",
    "$\\underline{FnVItems}$: The number of Food and Vegetable items bought by the customer.\n",
    "\n",
    "$\\underline{StaplesItems}$: The number of staple items bought by the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performing clustering, let us create a copy of the original loaded dataframe with only the relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:14:47.921703Z",
     "start_time": "2020-03-12T07:14:47.895904Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.drop(['Name','Cust_ID'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:16:32.907309Z",
     "start_time": "2020-03-12T07:16:32.713670Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:23:07.041498Z",
     "start_time": "2020-03-12T07:23:07.029480Z"
    }
   },
   "outputs": [],
   "source": [
    "ward_link = linkage(data,method = 'ward',metric='euclidean')\n",
    "ward_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:23:13.698625Z",
     "start_time": "2020-03-12T07:23:13.021524Z"
    }
   },
   "outputs": [],
   "source": [
    "Pleasedend_ward = dendrogram(ward_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some food for thought!!!! What is wrong with the above results??. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this step we are importing the Standard Scaler function to scale the data (Computing Z Scores) StandardScaler scales the data by subtracting the observation from the mean of the variable and dividing it by the standard deviation of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z = $\\frac{(x - \\mu)}{\\sigma}$\n",
    "\n",
    "###### Note: All the symbols follow the usual nomeclature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:27:00.492077Z",
     "start_time": "2020-03-12T07:26:58.474752Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:27:08.410193Z",
     "start_time": "2020-03-12T07:27:08.403327Z"
    }
   },
   "outputs": [],
   "source": [
    "#In this step we are defining an empty function. Going forward, you will be seeing this kind of definitions of functions from\n",
    "# the sklearn library\n",
    "\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:28:51.881248Z",
     "start_time": "2020-03-12T07:28:51.843857Z"
    }
   },
   "outputs": [],
   "source": [
    "#For 'sklearn' function we have to fit the function into the dataframe. \n",
    "#The backend of this function is that now we know the mean and standard deviation of the variables of this particular dataset.\n",
    "\n",
    "ss = scale.fit(data)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:29:07.568357Z",
     "start_time": "2020-03-12T07:29:07.556002Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#In this step we perform the standard scaling operation mentioned earlier.\n",
    "\n",
    "ss1 = ss.transform(data)\n",
    "ss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:30:12.589653Z",
     "start_time": "2020-03-12T07:30:12.579532Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:30:04.749076Z",
     "start_time": "2020-03-12T07:30:04.722847Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finally we go ahead and put the above values in a dataframe for easier understanding.\n",
    "\n",
    "pd.DataFrame(ss1,columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:31:59.654299Z",
     "start_time": "2020-03-12T07:31:59.627531Z"
    }
   },
   "outputs": [],
   "source": [
    "#FYI, We can go ahead and pass the following code snippet to perform all the functions of the standard scaler performed \n",
    "# above individually. Not required to pass them in individual steps\n",
    "\n",
    "data_scaled = pd.DataFrame(scale.fit_transform(data),columns=data.columns)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Performing Hierarchical Clustering with the 'scipy' package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:32:22.538334Z",
     "start_time": "2020-03-12T07:32:22.527801Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try to cluster the data with the Euclidean distance and Ward's method for linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:41:22.568514Z",
     "start_time": "2020-03-12T07:41:22.557851Z"
    }
   },
   "outputs": [],
   "source": [
    "wardlink = linkage(data_scaled,method = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:41:33.545934Z",
     "start_time": "2020-03-12T07:41:33.050422Z"
    }
   },
   "outputs": [],
   "source": [
    "warddend = dendrogram(wardlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet takes into account the Euclidean distance. If we are to perform the clustering algorithm by any other distance method we can perform the following code snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have visualized the number of clusters, we need to cluster the data according to their similarity metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:42:37.904307Z",
     "start_time": "2020-03-12T07:42:37.898744Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above library helps us to extract the cluster numbers by looking at the dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform this by two different methods.\n",
    "\n",
    "From the dendrogram, we see that 3 clusters are optimum. Thus, we are going to form 3 clusters based on the 'maxclust' criterion in the fcluster package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:45:00.480267Z",
     "start_time": "2020-03-12T07:44:59.499527Z"
    }
   },
   "outputs": [],
   "source": [
    "#Method 1\n",
    "#Uses Cophenetic distance using maxclust function\n",
    "#The cophenetic distance between two objects is the height of the dendrogram where the two branches that include the two objects merge into a single branch.\n",
    "\n",
    "clusters = fcluster(wardlink, 3, criterion='maxclust')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following second method to extract the number of clusters, we will use the 'distance' criterion. So, let us look at the optimum distance on the Y-axis of the dendrogam plot and extract the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:49:12.238345Z",
     "start_time": "2020-03-12T07:49:12.228912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method 2\n",
    "\n",
    "clusters = fcluster(wardlink, 4, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now go ahead and attach these clusters with the original dataframe and try to interpet it from a business perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:50:20.668542Z",
     "start_time": "2020-03-12T07:50:20.644959Z"
    }
   },
   "outputs": [],
   "source": [
    "df['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:50:21.132663Z",
     "start_time": "2020-03-12T07:50:21.114898Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us go ahead and export this particular into a csv and try to draw inferences from the clusters thus formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:54:35.500177Z",
     "start_time": "2020-03-12T07:54:35.487646Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('Hierarchical Clustering output.csv')\n",
    "\n",
    "#The above command is going export the file as a .csv into the location that the Jupyter Notebook is currently running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to profile the clusters with the mean of the spending on each category. This will give us an idea about the various clusters thus built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:56:53.607515Z",
     "start_time": "2020-03-12T07:56:53.355359Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['Cust_ID','Name'],axis=1)\n",
    "df_clust = df1.groupby('clusters').mean()\n",
    "df_clust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:57:38.123035Z",
     "start_time": "2020-03-12T07:57:38.098681Z"
    }
   },
   "outputs": [],
   "source": [
    "#This particular code snippet makes the above output into a data frame.\n",
    "\n",
    "df_clust = df_clust.reset_index()\n",
    "df_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:57:53.083151Z",
     "start_time": "2020-03-12T07:57:53.063038Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_freq = df['clusters'].value_counts().sort_index()\n",
    "cluster_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T07:57:53.617232Z",
     "start_time": "2020-03-12T07:57:53.595818Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clust['Frequency'] = cluster_freq.values\n",
    "df_clust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data frame, we know the frequency of the occurence of each clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following is an example of performing Hierarchical Clustering on the same data set. But in the following code snippet we have used 'Manhattan or cityblock' distance. Do try out other types of distance metrics along with different linkage methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T06:44:55.422603Z",
     "start_time": "2020-03-03T06:44:55.232210Z"
    }
   },
   "outputs": [],
   "source": [
    "dendrogram = dendrogram(linkage(data_scaled, method  = \"single\", metric='cityblock'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play around with the data and try to form clusters and build dendrogram by using different distance metrics and different linkage algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
